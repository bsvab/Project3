{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the CSV file again (assuming the correct path this time)\n",
    "df = pd.read_csv('updated_pressure_data_with_LatLon.csv')\n",
    "\n",
    "# Convert 'Time' column to datetime\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "# Splitting the DataFrame into separate ones for each layer\n",
    "layers = df['Layer'].unique()  # Get all unique layers\n",
    "layer_dfs = {layer: df[df['Layer'] == layer] for layer in layers}  # Dictionary to hold DataFrames for each layer\n",
    "\n",
    "# Now, process each layer's DataFrame to calculate delta pressures\n",
    "for layer, layer_df in layer_dfs.items():\n",
    "    # Ensure the DataFrame is sorted by 'Time' for each group of 'Longitude' and 'Latitude'\n",
    "    layer_df.sort_values(by='Time', inplace=True)\n",
    "\n",
    "    # Group by 'Longitude' and 'Latitude' to operate on each unique location\n",
    "    grouped = layer_df.groupby(['Longitude', 'Latitude'])\n",
    "\n",
    "    # Initialize an empty DataFrame to store the results for this layer\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through each group, calculate the delta pressure, and append to the results DataFrame\n",
    "    for (longitude, latitude), group in grouped:\n",
    "        # Find the reference pressure on the reference date (2017-01-01)\n",
    "        reference_pressure = group[group['Time'] == pd.Timestamp('2017-01-01')]['Pressure'].iloc[0]\n",
    "\n",
    "        # Calculate the delta pressure for each row in the group\n",
    "        group['Delta_Pressure'] = group['Pressure'] - reference_pressure\n",
    "\n",
    "        # Append the modified group to the results DataFrame\n",
    "        results_df = pd.concat([results_df, group], ignore_index=True)\n",
    "\n",
    "    # Save the results DataFrame for this layer to a CSV file\n",
    "    output_path = f'delta_pressure_{layer.replace(\" \", \"_\")}.csv'\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Print out the path to the saved file for verification\n",
    "    print(f'Saved delta pressures for {layer} to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file again\n",
    "df = pd.read_csv('/mnt/data/updated_pressure_data_with_LatLon.csv')\n",
    "\n",
    "# Convert 'Time' to datetime\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "# Filter the DataFrame for Layer_13 only\n",
    "layer_13_df = df[df['Layer'] == 'Layer_13']\n",
    "\n",
    "# For calculating delta pressure, we need to compare each pressure value to the first available pressure for that specific location within Layer_13\n",
    "# Group by Longitude and Latitude to handle each unique location\n",
    "grouped = layer_13_df.groupby(['Longitude', 'Latitude'])\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for name, group in grouped:\n",
    "    # Ensure the group is sorted by time to get the earliest pressure value correctly\n",
    "    group = group.sort(grouped.columns.drop('Pressure').tolist()).reset_index(drop=True)\n",
    "    \n",
    "    # The first pressure value in each group will be our reference\n",
    "    reference_pressure = group.iloc[0]['Pressure']\n",
    "    \n",
    "    # Calculate delta pressure for each row in the group\n",
    "    group['Delta_Pressure'] = group['Pressure'] - reference_pressure\n",
    "    \n",
    "    # Append the group with calculated delta pressures to the results DataFrame\n",
    "    results_df = pd.concat([results_df, group], ignore_index=True)\n",
    "\n",
    "# Now, results_df contains all data for Layer_13 with an additional column for delta pressure\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyproj\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Read the CSV file again\n",
    "df = pd.read_csv('updated_pressure_data_with_LatLon.csv')\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "layer_13_df = df[df['Layer'] == 'Layer_13']\n",
    "\n",
    "# Group by Longitude and Latitude for unique locations within Layer_13\n",
    "grouped = layer_13_df.groupby(['Longitude', 'Latitude'])\n",
    "\n",
    "# Initialize an empty DataFrame for results\n",
    "delta_pressure_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each group\n",
    "for (longitude, latitude), group in grouped:\n",
    "    # Filter to get the reference pressure on 2017-01-01 for each location\n",
    "    reference_pressure_row = group[group['Time'] == pd.Timestamp('2017-01-01')]\n",
    "    if not reference_pressure_row.empty:\n",
    "        reference_pressure = reference_pressure_row.iloc[0]['Pressure']\n",
    "        # Calculate delta pressure for each row in the group by subtracting the reference pressure\n",
    "        group['Delta_Pressure'] = group['Pressure'] - reference_pressure\n",
    "        # Append the processed group to the results DataFrame\n",
    "        delta_pressure_df = pd.concat([delta_pressure_df, group])\n",
    "\n",
    "# Resetting index of the final DataFrame\n",
    "delta_pressure_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the results DataFrame for this layer to a CSV file\n",
    "output_path = f'delta_pressure_layer13.csv'\n",
    "delta_pressure_df.to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "# Checking the first few rows of the final DataFrame\n",
    "delta_pressure_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a980d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_1.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_10.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_11.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_12.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_13.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_14.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_15.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_16.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_2.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_3.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_4.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_5.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_6.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_7.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_8.csv'),\n",
       " WindowsPath('/mnt/data/delta_pressures/delta_pressure_Layer_9.csv')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to calculate delta pressure\n",
    "def calculate_delta_pressure(group):\n",
    "    # Sort group by time\n",
    "    group = group.sort_values('Time')\n",
    "    # Get the reference pressure from the first date (assumed to be the earliest in the group)\n",
    "    reference_pressure = group.iloc[0]['Pressure']\n",
    "    # Calculate delta pressure\n",
    "    group['Delta_Pressure'] = group['Pressure'] - reference_pressure\n",
    "    return group\n",
    "\n",
    "# Read CSV\n",
    "df_path = 'updated_pressure_data_with_LatLon.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# Convert 'Time' to datetime\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "# Get unique layers\n",
    "layers = df['Layer'].unique()\n",
    "\n",
    "\n",
    "# Calculate delta pressure for each layer and save to a separate CSV\n",
    "for layer in layers:\n",
    "    layer_df = df[df['Layer'] == layer]\n",
    "    # Group by 'Longitude' and 'Latitude' to handle each location separately\n",
    "    grouped = layer_df.groupby(['Longitude', 'Latitude'])\n",
    "    # Apply the calculate_delta_pressure function to each group\n",
    "    delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
    "    # Save to CSV\n",
    "    output_file = f'delta_pressure_{layer}.csv'\n",
    "    delta_df.to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7068a0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Time  Pressure    Layer   Longitude   Latitude  Delta_Pressure\n",
       " 0 2017-01-01   7952.25  Layer_1 -103.777418  31.533703             0.0\n",
       " 1 2017-01-01   7970.05  Layer_1 -103.760446  31.534198             0.0\n",
       " 2 2017-01-01   7658.27  Layer_1 -103.998653  31.541595             0.0\n",
       " 3 2017-01-01   7754.00  Layer_1 -103.981681  31.542119             0.0\n",
       " 4 2017-01-01   7828.24  Layer_1 -103.964708  31.542642             0.0,\n",
       " 'delta_pressure_all_layers.csv')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate delta pressure\n",
    "def calculate_delta_pressure(group):\n",
    "    # Sort group by time\n",
    "    group = group.sort_values('Time')\n",
    "    # Get the reference pressure from the first date (assumed to be the earliest in the group)\n",
    "    reference_pressure = group.iloc[0]['Pressure']\n",
    "    # Calculate delta pressure\n",
    "    group['Delta_Pressure'] = group['Pressure'] - reference_pressure\n",
    "    return group\n",
    "\n",
    "# Read CSV\n",
    "df_path = 'updated_pressure_data_with_LatLon.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# Convert 'Time' to datetime\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "# Get unique layers\n",
    "layers = df['Layer'].unique()\n",
    "\n",
    "# Initialize a DataFrame to store all the delta pressures\n",
    "all_layers_delta_df = pd.DataFrame()\n",
    "\n",
    "# Calculate delta pressure for each layer and append to the all_layers_delta_df DataFrame\n",
    "for layer in layers:\n",
    "    layer_df = df[df['Layer'] == layer]\n",
    "    # Group by 'Longitude' and 'Latitude' to handle each location separately\n",
    "    grouped = layer_df.groupby(['Longitude', 'Latitude'])\n",
    "    # Apply the calculate_delta_pressure function to each group\n",
    "    delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
    "    # Append to the all_layers_delta_df DataFrame\n",
    "    all_layers_delta_df = pd.concat([all_layers_delta_df, delta_df], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file without headers for subsequent rows\n",
    "output_file = 'delta_pressure_all_layers.csv'\n",
    "all_layers_delta_df.to_csv(output_file, index=False)\n",
    "\n",
    "all_layers_delta_df.head(), output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2bfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
